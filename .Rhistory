for(i in 1:nr) {
for(j in 1:nr) {
cos <- crossprod(coll.PPMI[i, ], coll.PPMI[j, ])/sqrt(crossprod(coll.PPMI[i,
]) * crossprod(coll.PPMI[j, ]))
m[i,j] <- cos
m[j,i] <- cos
}
print(i)
}
# export
saveRDS(m, "m_approx.Rds")
m <- readRDS("m_approx.Rds")
# get distances
m2 <- 1 - (m / max(m[m<1]))
# backup copy
m2_matrix <- m2
# as.dist
m2 <- as.dist(m2)
# as matrix
m2_matrix <- as.matrix(m2, varnames = c("row", "col"))
# mds
m3 <- cmdscale(m2)
m3 <- rownames_to_column(as.data.frame(m3))
colnames(m3) <- c("Lemma", "dim1", "dim2")
# clustering
for(i in 1:20) {
clust <- cluster::pam(m2, i)
print(clust$silinfo$avg.width)
}
m2_clust <- cluster::pam(m2, 20)
m2_cluster <- m2_clust$clustering %>% as.data.frame()
m2_cluster <- rownames_to_column(m2_cluster)
colnames(m2_cluster) <- c("Lemma", "Cluster")
# combine df with cluster info --------------------------------------------
m3 <- left_join(m3, m2_cluster)
# add frequency data
m3$freq <- numeric(nrow(m3))
approx <- read_xlsx("approx_annotated.xlsx")
approx <- filter(approx, WORD.CLASS=="A")
approx <- mutate(approx, Lemma = gsub("approx\\-?", "", approx$Key, ignore.case = T))
# add frequency data
m3$freq <- numeric(nrow(m3))
approx <- read_xlsx("approx_annotated.xlsx")
approx_tbl
m3
left_join(m3, approx_tbl)
left_join(m3, unique(select(approx_tbl, Lemma, n_all)))
m3
left_join(m3, unique(select(approx_tbl, Lemma, n_all)))
142+33
approx_tbl
m3
approx_tbl2
left_join(m3, approx_tbl2)
# mds
m3 <- cmdscale(m2)
m3 <- rownames_to_column(as.data.frame(m3))
colnames(m3) <- c("Lemma", "dim1", "dim2")
# clustering
for(i in 1:20) {
clust <- cluster::pam(m2, i)
print(clust$silinfo$avg.width)
}
m2_clust <- cluster::pam(m2, 20)
m2_cluster <- m2_clust$clustering %>% as.data.frame()
m2_cluster <- rownames_to_column(m2_cluster)
colnames(m2_cluster) <- c("Lemma", "Cluster")
# combine df with cluster info --------------------------------------------
m3 <- left_join(m3, m2_cluster)
# add frequency data
m3 <-left_join(m3, approx_tbl2)
m3
approx_tbl %>% filter(prefix == "pseudo")
approx_tbl %>% filter(prefix == "pseudo") %>% select(Lemma, n)
?rename
approx_tbl %>% filter(prefix == "pseudo") %>% select(Lemma, n) %>% rename(n_pseudo = n)
approx_tbl %>% filter(prefix == "pseudo") %>% select(Lemma, n) %>% rename(n_pseudo = n)
approx_tbl %>% filter(prefix == "pseudo") %>% ungroup %>% select(Lemma, n) %>% rename(n_pseudo = n)
left_join(m3, approx_tbl %>% filter(prefix == "pseudo") %>% ungroup %>% select(Lemma, n) %>% rename(n_pseudo = n))
left_join(m3, approx_tbl %>% filter(prefix == "pseudo") %>% ungroup %>% select(Lemma, n) %>% rename(n_pseudo = n)) %>% replace_na(n_pseudo = 0)
left_join(m3, approx_tbl %>% filter(prefix == "pseudo") %>% ungroup %>% select(Lemma, n) %>% rename(n_pseudo = n)) %>% replace_na(list(n_pseudo = 0))
m3
left_join(m3, approx_tbl %>% filter(prefix == "pseudo") %>%
ungroup %>% select(Lemma, n) %>%
rename(n_pseudo = n)) %>%
replace_na(list(n_pseudo = 0), all.x = T)
left_join(m3, approx_tbl %>% filter(prefix == "pseudo") %>%
ungroup %>% select(Lemma, n) %>%
rename(n_pseudo = n)) %>%
replace_na(list(n_pseudo = 0))
left_join(m3, approx_tbl %>% filter(prefix == "pseudo") %>%
ungroup %>% select(Lemma, n) %>%
rename(n_pseudo = n)))
left_join(m3, approx_tbl %>% filter(prefix == "pseudo") %>%
ungroup %>% select(Lemma, n) %>%
rename(n_pseudo = n))
left_join(m3, approx_tbl %>% filter(prefix == "pseudo") %>%
ungroup %>% unique %>% select(Lemma, n) %>%
rename(n_pseudo = n))
left_join(m3, approx_tbl %>% filter(prefix == "pseudo" & WORD.CLASS == "N") %>%
ungroup %>% unique %>% select(Lemma, n) %>%
rename(n_pseudo = n))
left_join(m3, approx_tbl %>% filter(prefix == "pseudo" & WORD.CLASS == "N") %>%
ungroup %>% unique %>% select(Lemma, n) %>%
rename(n_pseudo = n) %>% replace_na(list(n_pseudo = 0)))
left_join(m3, approx_tbl %>% filter(prefix == "pseudo" & WORD.CLASS == "N") %>%
ungroup %>% unique %>% select(Lemma, n) %>%
rename(n_pseudo = n))) %>% replace_na(list(n_pseudo = 0)
rename(n_pseudo = n)) %>% replace_na(list(n_pseudo = 0)
left_join(m3, approx_tbl %>% filter(prefix == "pseudo" & WORD.CLASS == "N") %>%
ungroup %>% unique %>% select(Lemma, n) %>%
rename(n_pseudo = n))
left_join(m3, approx_tbl %>% filter(prefix == "pseudo" & WORD.CLASS == "N") %>%
ungroup %>% unique %>% select(Lemma, n) %>%
rename(n_pseudo = n)) %>% colnames
left_join(m3, approx_tbl %>% filter(prefix == "pseudo" & WORD.CLASS == "N") %>%
ungroup %>% unique %>% select(Lemma, n) %>%
rename(n_pseudo = n)) %>% replace_na(list(n_pseudo = 0))
m3 <- left_join(m3, approx_tbl %>% filter(prefix == "pseudo" & WORD.CLASS == "N") %>%
ungroup %>% unique %>% select(Lemma, n) %>%
rename(n_pseudo = n)) %>% replace_na(list(n_pseudo = 0))
left_join(m3, approx_tbl %>% filter(prefix == "quasi" & WORD.CLASS == "N") %>%
ungroup %>% unique %>% select(Lemma, n) %>%
rename(n_quasi = n)) %>% replace_na(list(n_quasi = 0))
left_join(m3, (approx_tbl %>% filter(prefix == "quasi" & WORD.CLASS == "N") %>%
ungroup %>% unique %>% select(Lemma, n) %>%
rename(n_quasi = n))) %>% replace_na(list(n_quasi = 0))
left_join(m3, (approx_tbl %>% filter(prefix == "quasi" & WORD.CLASS == "N") %>%
ungroup %>% unique %>% select(Lemma, n) %>%
rename(n_quasi = n)), all.x = T) %>% replace_na(list(n_quasi = 0))
left_join(m3, (approx_tbl %>% filter(prefix == "quasi" & WORD.CLASS == "N") %>%
ungroup %>% unique %>% select(Lemma, n) %>%
rename(n_quasi = n)), all.y = T) %>% replace_na(list(n_quasi = 0))
left_join(m3, (approx_tbl %>% filter(prefix == "quasi" & WORD.CLASS == "N") %>%
ungroup %>% unique %>% select(Lemma, n) %>%
rename(n_quasi = n)), all.x = T) %>% replace_na(list(n_quasi = 0))
m3
?left_join
?left_join
approx_tbl %>% filter(prefix == "quasi" & WORD.CLASS == "N") %>%
ungroup
approx_tbl_quasi <- (approx_tbl %>% filter(prefix == "quasi" & WORD.CLASS == "N") %>%
ungroup %>% unique %>% select(Lemma, n) %>%
rename(n_quasi = n))
left_join(m3, approx_tbl_quasi, all.x = T) %>% replace_na(list(n_quasi = 0))
merge(m3, approx_tbl_quasi, all.x = T) %>% replace_na(list(n_quasi = 0))
merge(m3, approx_tbl_quasi, all.x = T)
m3
merge(m3, approx_tbl_quasi, all.x = T)
merge(m3, approx_tbl_quasi, all = T)
merge(m3, approx_tbl_quasi, all.x = T,)
left_join(m3, (approx_tbl %>% filter(prefix == "quasi" & WORD.CLASS == "N") %>%
ungroup %>% unique %>% select(Lemma, n) %>%
rename(n_quasi = n)), all.x = T) %>% replace_na(list(n_quasi = 0))
142+14
m3 <- left_join(m3, (approx_tbl %>% filter(prefix == "quasi" & WORD.CLASS == "N") %>%
ungroup %>% unique %>% select(Lemma, n) %>%
rename(n_quasi = n)), all.x = T) %>% replace_na(list(n_quasi = 0))
m3 <- left_join(m3, approx_tbl %>% filter(prefix == "near" & WORD.CLASS == "N") %>%
ungroup %>% unique %>% select(Lemma, n) %>%
rename(n_near = n)) %>% replace_na(list(n_near = 0))
m3
m3$n_pseudo
m3$n_pseudo + m3$n_near + m3$n_quasi
m3$n_near/m3$n_all
m3$n_pseudo/m3$n_all
m3$n_quasi/m3$n_all
m3$near_rel <- m3$n_near/m3$n_all
m3$pseudo_rel <- m3$n_pseudo/m3$n_all
m3$quasi_rel <- m3$n_quasi/m3$n_all
paste0("rgb(", m3$near_rel, "," m3$pseudo_rel)
paste0("rgb(", m3$near_rel, ",", m3$pseudo_rel)
paste0("rgb(", m3$near_rel, ",", m3$pseudo_rel, ",", m3$quasi_rel, ")")
m3$col <- paste0("rgb(", m3$near_rel, ",", m3$pseudo_rel, ",", m3$quasi_rel, ")")
# plot
set.seed(1249220)
ggplot(m3, aes(x = dim1, y = dim2, col = col, label = Lemma)) +
geom_text_repel(aes(size = log1p(freq)/2), max.overlaps = 65) +
guides(col = 'none', size = 'none') + theme_bw() +
scale_color_manual(values = viridis::mako(20))
m3$n_all
# plot
set.seed(1249220)
ggplot(m3, aes(x = dim1, y = dim2, col = col, label = Lemma)) +
geom_text_repel(aes(size = log1p(n_all)/2), max.overlaps = 65) +
guides(col = 'none', size = 'none') + theme_bw() +
scale_color_manual(values = viridis::mako(20))
m3
ggplot(m3, aes(x = dim1, y = dim2, label = Lemma)) +
geom_text_repel(aes(size = log1p(n_all)/2), max.overlaps = 65) +
guides(col = 'none', size = 'none') + theme_bw() +
scale_color_manual(values = viridis::mako(20))
ggplot(m3, aes(x = dim1, y = dim2, col = col, label = Lemma)) +
geom_text_repel(aes(size = log1p(n_all)/2), max.overlaps = 65) +
guides(col = 'none', size = 'none') + theme_bw()
ggplot(m3, aes(x = dim1, y = dim2, col = col, label = Lemma)) +
geom_text_repel(aes(size = log1p(n_all)/2), max.overlaps = 65) +
guides(col = 'none', size = 'none') + theme_bw() +
scale_color_manual(values = col)
ggplot(m3, aes(x = dim1, y = dim2, col = col, label = Lemma)) +
geom_text_repel(aes(size = log1p(n_all)/2), max.overlaps = 65) +
guides(col = 'none', size = 'none') + theme_bw() +
scale_color_manual(values = m3$col)
m3$col
levels(factor(m3$col))
ggplot(m3, aes(x = dim1, y = dim2, col = col, label = Lemma)) +
geom_text_repel(aes(size = log1p(n_all)/2), max.overlaps = 65) +
guides(col = 'none', size = 'none') + theme_bw() +
scale_color_manual(values = levels(factor(m3$col)))
ggplot(m3, aes(x = dim1, y = dim2, col = col, label = Lemma)) +
geom_text_repel(aes(size = log1p(n_all)/2), max.overlaps = 65) +
guides(col = 'none', size = 'none') + theme_bw() +
scale_color_manual(values = c(levels(factor(m3$col))))
ggplot(m3, aes(x = dim1, y = dim2, col = col, label = Lemma)) +
geom_text_repel(aes(size = log1p(n_all)/2), max.overlaps = 65) +
guides(col = 'none', size = 'none') + theme_bw() +
scale_color_manual(values = unique(m3$col)))
ggplot(m3, aes(x = dim1, y = dim2, col = col, label = Lemma)) +
geom_text_repel(aes(size = log1p(n_all)/2), max.overlaps = 65) +
guides(col = 'none', size = 'none') + theme_bw() +
scale_color_manual(values = unique(m3$col))
ggplot(m3, aes(x = dim1, y = dim2, col = col, label = Lemma)) +
geom_text_repel(aes(size = log1p(n_all)/2), max.overlaps = 65) +
guides(col = 'none', size = 'none') + theme_bw()
m3$col
ggplot(m3, aes(x = dim1, y = dim2, col = col, label = Lemma)) +
geom_text_repel(aes(size = log1p(n_all)/2), max.overlaps = 65) +
guides(col = 'none', size = 'none') + theme_bw() +
scale_color_manual(values = rgb(0,1,3))
ggplot(m3, aes(x = dim1, y = dim2, col = col, label = Lemma)) +
geom_text_repel(aes(size = log1p(n_all)/2), max.overlaps = 65) +
guides(col = 'none', size = 'none') + theme_bw() +
scale_color_manual(values = rgb(0,1,0))
ggplot(m3, aes(x = dim1, y = dim2, col = col, label = Lemma)) +
geom_text_repel(aes(size = log1p(n_all)/2), max.overlaps = 65) +
guides(col = 'none', size = 'none') + theme_bw() +
scale_color_manual(values = unique(m3$col))
m3$col
m3$col %>% unique()
round(m3$near_rel)
round(m3$near_rel, digits = 3)
prettyNum(m3$near_rel, digits = 3)
paste0("rgb(", prettyNum(m3$near_rel, digits = 3), ",", prettyNum(m3$pseudo_rel, digits = 3), ",", prettyNum(m3$quasi_rel, digits = 3), ")")
m3$col <- paste0("rgb(", prettyNum(m3$near_rel, digits = 3), ",", prettyNum(m3$pseudo_rel, digits = 3), ",", prettyNum(m3$quasi_rel, digits = 3), ")")
ggplot(m3, aes(x = dim1, y = dim2, col = col, label = Lemma)) +
geom_text_repel(aes(size = log1p(n_all)/2), max.overlaps = 65) +
guides(col = 'none', size = 'none') + theme_bw() +
scale_color_manual(values = unique(m3$col))
m3$col <- paste0("rgb(", prettyNum(m3$near_rel, digits = 2), ",", prettyNum(m3$pseudo_rel, digits = 2), ",", prettyNum(m3$quasi_rel, digits = 2), ")")
ggplot(m3, aes(x = dim1, y = dim2, col = col, label = Lemma)) +
geom_text_repel(aes(size = log1p(n_all)/2), max.overlaps = 65) +
guides(col = 'none', size = 'none') + theme_bw() +
scale_color_manual(values = unique(m3$col))
ggplot(m3, aes(x = dim1, y = dim2, label = Lemma)) +
geom_text_repel(aes(size = log1p(n_all)/2, col = col), max.overlaps = 65) +
guides(col = 'none', size = 'none') + theme_bw()
ggplot(m3, aes(x = dim1, y = dim2, label = Lemma)) +
geom_text_repel(aes(size = log1p(n_all)/2, col = col), max.overlaps = 65) +
guides(col = 'none', size = 'none') + theme_bw() +
scale_color_manual(values = rep("rgb(1,0,0)", 47))
paste0(sample(c(LETTERS, letters, 0-9)))
paste0(sample(c(LETTERS, letters, 0-9)), sep="")
paste0(sample(c(LETTERS, letters, 0-9)), collapse="")
paste0(sample(c(LETTERS, letters, 0-9), 8), collapse="")
?coalesce
library(tidyverse)
?coalesce
159347+6080+18270+930+18880+930
tx <- "R is a programming language for statistical computing and graphics supported by the R Core Team and the R Foundation for Statistical Computing. Created by statisticians Ross Ihaka and Robert Gentleman, R is used among data miners and statisticians for data analysis and developing statistical software. Users have created packages to augment the functions of the R language.
Polls, data mining surveys, and studies of scholarly literature databases show that R is highly popular;[6] since January 2022, R ranks 12th in the TIOBE index, a measure of programming language popularity.[7]
The official R software environment is an open-source free software environment within the GNU package, available under the GNU General Public License. It is written primarily in C, Fortran, and R itself (partially self-hosting). Precompiled executables are provided for various operating systems. R has a command line interface. Multiple third-party graphical user interfaces are also available, such as RStudio, an integrated development environment, and Jupyter, a notebook interface. "
tx
gsub("\\[[0-9]\\]", "", tx)
?gsub
gsub("\[[0-9]\]", "", tx)
gsub("\\[[0-9]\\]", "", tx)
"\\[bla"
cat("\\bla")
print("\\bla")
?cat
cat("\\bla")
cat("\\[bla")
library(psy)
library(readxl)
library(tidyverse)
library(readxl)
library(psy)
read_xlsx("/Users/stefanhartmann/sciebo/Projekte/Graphemic variation/Variation_Abiturkorpus/sfb_fehler.xlsx")
d <- read_xlsx("/Users/stefanhartmann/sciebo/Projekte/Graphemic variation/Variation_Abiturkorpus/sfb_fehler.xlsx")
?kappa
d <- read_xlsx("/Users/stefanhartmann/sciebo/Projekte/Graphemic variation/Variation_Abiturkorpus/sfb_fehler.xlsx")
View(d)
View(d)
d <- read_xlsx("/Users/stefanhartmann/sciebo/Projekte/Graphemic variation/Variation_Abiturkorpus/sfb_fehler.xlsx", sheet = "Fehler")
ckappa(cbind(d$`Bsfin Kategorie`, d$`Bsfin Kategorie_SH`))
16+13+16+12+14+15+17+12+8
17+14+14+15+15+5+9+8+6
13+14+12+9+15+8+13+7+5
11+9+16+11+12+13+14+12+3
19+14+12+12+18+13+17+10+4
19+20+20+16+20+24+20+12+8
12+8+12+14+16+13+8+8+6
16+11+16+14+15+10
16+11+16+14+15+10+14+11+8
11+7+16+15+11+13+15+7+8
14+14+12+7.5+8+6+15+7+5
17+10+10+13.5+14+11+16+10+5
19+18+20+16+13+20+15+11+8
19+15+20+13+14+13+18+12+5
18+11+8+14+11+10+18+12+6
19+10+15+12+16+15+13+16
11+5+9+8+14+7+11+12
8+13+11+14+19+17+17+16+20
5+6+5+9+5+14+12+15+10
8+14+12+15+14+14+14+20+12
8+16+6+10+12+10+20+11+8
5+7+8+10+9+12+4
13+9+12+17+9
15+17+10+23+19+8
18+12+10+16+15+8
18+7+8+24+15+8
17+19+10+18+18+8
13+5+13+16+16+4
18+12+12+24+17+8
20+17+11+23+19+8
15+10+13+24+16+8
15+19+15+12+11+22+17+12+8
3500*0.8
3500*0.008
10*1080
10800/60
9+11+7+6+16+15+19+20+16
14+9+11+17+12+13+8+10
19+16+16+16+18+24+20+12+6
12+15+12+20+20+18+20+19+16
8+13+9+20+17+15+4
15+20+20+20+20+18+20+24
13+18+19+20+20+19+18+24
65/3
(65/3)/12
4.3/152
4.3/152*1e6
3.8e6/147
3.8e6/147*1e6
152/4.2*1e6
152/(4.2*1e6)
(152/(4.2*1e6))*1e6
(147/(3.8*1e6))*1e6
3345897*(1/320)
5728-34
2022-2004
52*30
514.37*4
474.80*4
install.packages("polmineR")
install.packages("GermaParl")
use("GermaParl")
library(polmineR)
use("GermaParl")
corpus()
size("GERMAPARL")
size(GERMAPARL)
size("GERMAPARLMINI")
?corpus
devtools::install_github("PolMine/GermaParl", ref = "dev")
setwd("~/sciebo/Futurkonstruktionen/REN/CoraXML_ReN")
library(tidyverse)
# read data
d <- readLines("ReN_anno_2019-08-14/")
# read data
d <- readLines("ReN_anno_2019-08-14/Agneta_Willeken.xml")
d
# get metadata
grep("<cora-header name>", d, value = T)
# get metadata
grep("<cora-header name", d, value = T)
# get metadata
gsub(".*name=\"", "", grep("<cora-header name", d, value = T))
# get metadata
gsub("\".*", "", gsub(".*name=\"", "", grep("<cora-header name", d, value = T)))
# get metadata
header_name <- gsub("\".*", "", gsub(".*name=\"", "", grep("<cora-header name", d, value = T)))
# get tokens
gsub("dipl id", d)
# get tokens
grep("dipl id", d)
# get tokens
ids <- grep("dipl id", d)
morph <- grep("morph tag")
morph <- grep("morph tag")
morph <- grep("morph tag", d)
trm(ids)
rm(ids)
# get tokens
grep("<token id", d)
# get tokens
token_start <- grep("<token id", d)
token_end   <- grep("</token", d)
# extract values
d[token_start:token_end]
# extract values
d[token_start[1]:token_end[1]]
# extract values
cur <-d[token_start[1]:token_end[1]]
# empty vectors for dipl, lemma, POS, morph
dipl <- lemma <- pos <- morph <- character(length(token_start))
cur <-d[token_start[1]:token_end[1]]
cur
# empty vectors for dipl, lemma, POS, morph
token_id <- dipl <- lemma <- pos <- morph <- character(length(token_start))
# empty vectors for dipl, lemma, POS, morph
tibble(
token_id = character(length(token_start)),
dipl     = character(length(token_start)),
lemma    = character(length(token_start)),
pos      = character(length(token_start)),
morph    = character(length(token_start))
)
# empty vectors for dipl, lemma, POS, morph
cur_tbl <- tibble(
token_id = character(length(token_start)),
dipl     = character(length(token_start)),
lemma    = character(length(token_start)),
pos      = character(length(token_start)),
morph    = character(length(token_start))
)
cur <-d[token_start[1]:token_end[1]]
grep("token_id", cur)
grep("token id", cur)
cur[1]
cur[grep("token id", cur)]
gsub(".*<token id=\"", "", cur[grep("token id", cur)])
gsub("\"", "", gsub(".*<token id=\"", "", cur[grep("token id", cur)]))
gsub("\".*", "", gsub(".*<token id=\"", "", cur[grep("token id", cur)]))
cur
length(grep(".*<token id=\"", cur))
if(length(grep(".*<token id=\"", cur)) > 0) {
gsub("\".*", "", gsub(".*<token id=\"", "", cur[grep("token id", cur)]))
}
cur
gsub("\".*", "", gsub(".*<lemma tag=\"", "", cur[grep("lemma tag", cur)]))
gsub("\".*", "", gsub(".*<morph tag=\"", "", cur[grep("morph tag", cur)]))
gsub("\".*", "", gsub(".*<pos tag=\"", "", cur[grep("pos tag", cur)]))
length(grep(".*<token id=\".*trans", cur)
)
gsub("\".*", "", gsub(".*<trans=\"", "", cur[grep("token id", cur)]))
cur[grep("token id", cur)
)
cur[grep("token id", cur)]
gsub("\".*", "", gsub(".*trans=\"", "", cur[grep("token id", cur)]))
for(i in 1:length(token_start)) {
cur <-d[token_start[i]:token_end[i]]
if(length(grep(".*<token id=\"", cur)) > 0) {
cur_tbl$token_id[i] <- gsub("\".*", "", gsub(".*<token id=\"", "", cur[grep("token id", cur)]))
} else {
cur_tbl$token_id[i] <- "-"
}
if(length(grep(".*<token id=\".*trans", cur)) > 0) {
cur_tbl$dipl[i] <- gsub("\".*", "", gsub(".*trans=\"", "", cur[grep("token id", cur)]))
} else {
cur_tbl$dipl[i] <- "-"
}
if(length(grep(".*<lemma tag=\"", cur)) > 0) {
cur_tbl$lemma[i] <- gsub("\".*", "", gsub(".*<lemma tag=\"", "", cur[grep("lemma tag", cur)]))
} else {
cur_tbl$lemma[i] <- "-"
}
if(length(grep(".*<morph tag=\"", cur)) > 0) {
cur_tbl$morph[i] <- gsub("\".*", "", gsub(".*<morph tag=\"", "", cur[grep("morph tag", cur)]))
} else {
cur_tbl$morph[i] <- "-"
}
if(length(grep(".*<pos tag=\"", cur)) > 0) {
cur_tbl$morph[i] <- gsub("\".*", "", gsub(".*<pos tag=\"", "", cur[grep("pos tag", cur)]))
} else {
cur_tbl$morph[i] <- "-"
}
print(i)
}
warnings()
cur_tbl
for(i in 1:length(token_start)) {
cur <-d[token_start[i]:token_end[i]]
if(length(grep(".*<token id=\"", cur)) > 0) {
cur_tbl$token_id[i] <- gsub("\".*", "", gsub(".*<token id=\"", "", cur[grep("token id", cur)]))
} else {
cur_tbl$token_id[i] <- "-"
}
if(length(grep(".*<token id=\".*trans", cur)) > 0) {
cur_tbl$dipl[i] <- gsub("\".*", "", gsub(".*trans=\"", "", cur[grep("token id", cur)]))
} else {
cur_tbl$dipl[i] <- "-"
}
if(length(grep(".*<lemma tag=\"", cur)) > 0) {
cur_tbl$lemma[i] <- gsub("\".*", "", gsub(".*<lemma tag=\"", "", cur[grep("lemma tag", cur)]))
} else {
cur_tbl$lemma[i] <- "-"
}
if(length(grep(".*<morph tag=\"", cur)) > 0) {
cur_tbl$morph[i] <- gsub("\".*", "", gsub(".*<morph tag=\"", "", cur[grep("morph tag", cur)]))
} else {
cur_tbl$morph[i] <- "-"
}
if(length(grep(".*<pos tag=\"", cur)) > 0) {
cur_tbl$pos[i] <- gsub("\".*", "", gsub(".*<pos tag=\"", "", cur[grep("pos tag", cur)]))
} else {
cur_tbl$pos[i] <- "-"
}
print(i)
}
warnings()
View(cur_tbl)
