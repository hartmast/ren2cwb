"ren.vrt", row.names = F, col.names = F, quote = F, append = T)
# file header
write.table(c("<?xml version=\"1.0\" encoding=\"UTF-8\"?>", "<corpus>"),
"ren.vrt", row.names = F, col.names = F, quote = F)
write.table(text_header,
"ren.vrt", row.names = F, col.names = F, quote = F, append = T)
write.table(cur_tbl,
"ren.vrt", sep = "\t", row.names = F, col.names = F, quote = F, append = T)
write.table(c("</text>", "</corpus>"),
"ren.vrt", row.names = F, col.names = F, quote = F, append = T)
library(tidyverse)
# read data
d <- readLines("ReN_anno_2019-08-14/Agneta_Willeken.xml")
# get metadata
header_name <- gsub("\".*", "", gsub(".*name=\"", "", grep("<cora-header name", d, value = T)))
# get header
header_start <- grep("<header", d)
header_end   <- grep("</header", d)
hdr <- d[header_start:header_end]
hdr <- sub(":", "=\"", hdr)
hdr <- gsub("(?<=$)", "\"", hdr, perl = T)
text_header <- paste0("<text id=\"", header_name, "\"", gsub("text=\"", "text_name=\"", gsub("</?header>", "", paste0(hdr, collapse = " "))), ">", collapse = " ")
# get tokens
token_start <- grep("<token id", d)
token_end   <- grep("</token", d)
# empty table for dipl, lemma, POS, morph
cur_tbl <- tibble(
word     = character(length(token_start)),
token_id = character(length(token_start)),
dipl     = character(length(token_start)),
lemma    = character(length(token_start)),
pos      = character(length(token_start)),
morph    = character(length(token_start))
)
# extract values
for(i in 1:length(token_start)) {
cur <-d[token_start[i]:token_end[i]]
if(length(grep(".*<token id=\"", cur)) > 0) {
cur_tbl$token_id[i] <- gsub("\".*", "", gsub(".*<token id=\"", "", cur[grep("token id", cur)]))
} else {
cur_tbl$token_id[i] <- "-"
}
if(length(grep(".*<token id=\".*trans", cur)) > 0) {
cur_tbl$dipl[i] <- gsub("\".*", "", gsub(".*trans=\"", "", cur[grep("token id", cur)]))
} else {
cur_tbl$dipl[i] <- "-"
}
if(length(grep(".*<token id=\".*trans", cur)) > 0) {
cur_tbl$word[i] <- gsub("\".*", "", gsub(".*trans=\"", "", cur[grep("token id", cur)]))
} else {
cur_tbl$word[i] <- "-"
}
if(length(grep(".*<lemma tag=\"", cur)) > 0) {
cur_tbl$lemma[i] <- gsub("\".*", "", gsub(".*<lemma tag=\"", "", cur[grep("lemma tag", cur)]))
} else {
cur_tbl$lemma[i] <- "-"
}
if(length(grep(".*<morph tag=\"", cur)) > 0) {
cur_tbl$morph[i] <- gsub("\".*", "", gsub(".*<morph tag=\"", "", cur[grep("morph tag", cur)]))
} else {
cur_tbl$morph[i] <- "-"
}
if(length(grep(".*<pos tag=\"", cur)) > 0) {
cur_tbl$pos[i] <- gsub("\".*", "", gsub(".*<pos tag=\"", "", cur[grep("pos tag", cur)]))
} else {
cur_tbl$pos[i] <- "-"
}
}
# create CWB file
# file header
write.table(c("<?xml version=\"1.0\" encoding=\"UTF-8\"?>", "<corpus>"),
"ren.vrt", row.names = F, col.names = F, quote = F)
write.table(text_header,
"ren.vrt", row.names = F, col.names = F, quote = F, append = T)
write.table(cur_tbl,
"ren.vrt", sep = "\t", row.names = F, col.names = F, quote = F, append = T)
write.table(c("</text>", "</corpus>"),
"ren.vrt", row.names = F, col.names = F, quote = F, append = T)
cur_tbl
# list files
list.files("ReN_anno_2019-08-14/")
# list files
f <- list.files("ReN_anno_2019-08-14/", full.names = T)
# read data
d <- readLines(f[1])
# list files
f <- list.files("ReN_anno_2019-08-14/", full.names = T)
for(j in 1:length(f)) {
# read data
d <- readLines(f[j])
# get metadata
header_name <- gsub("\".*", "", gsub(".*name=\"", "", grep("<cora-header name", d, value = T)))
# get header
header_start <- grep("<header", d)
header_end   <- grep("</header", d)
hdr <- d[header_start:header_end]
hdr <- sub(":", "=\"", hdr)
hdr <- gsub("(?<=$)", "\"", hdr, perl = T)
text_header <- paste0("<text id=\"", header_name, "\"", gsub("text=\"", "text_name=\"", gsub("</?header>", "", paste0(hdr, collapse = " "))), ">", collapse = " ")
# get tokens
token_start <- grep("<token id", d)
token_end   <- grep("</token", d)
# empty table for dipl, lemma, POS, morph
cur_tbl <- tibble(
word     = character(length(token_start)),
token_id = character(length(token_start)),
dipl     = character(length(token_start)),
lemma    = character(length(token_start)),
pos      = character(length(token_start)),
morph    = character(length(token_start))
)
# extract values
for(i in 1:length(token_start)) {
cur <-d[token_start[i]:token_end[i]]
if(length(grep(".*<token id=\"", cur)) > 0) {
cur_tbl$token_id[i] <- gsub("\".*", "", gsub(".*<token id=\"", "", cur[grep("token id", cur)]))
} else {
cur_tbl$token_id[i] <- "-"
}
if(length(grep(".*<token id=\".*trans", cur)) > 0) {
cur_tbl$dipl[i] <- gsub("\".*", "", gsub(".*trans=\"", "", cur[grep("token id", cur)]))
} else {
cur_tbl$dipl[i] <- "-"
}
if(length(grep(".*<token id=\".*trans", cur)) > 0) {
cur_tbl$word[i] <- gsub("\".*", "", gsub(".*trans=\"", "", cur[grep("token id", cur)]))
} else {
cur_tbl$word[i] <- "-"
}
if(length(grep(".*<lemma tag=\"", cur)) > 0) {
cur_tbl$lemma[i] <- gsub("\".*", "", gsub(".*<lemma tag=\"", "", cur[grep("lemma tag", cur)]))
} else {
cur_tbl$lemma[i] <- "-"
}
if(length(grep(".*<morph tag=\"", cur)) > 0) {
cur_tbl$morph[i] <- gsub("\".*", "", gsub(".*<morph tag=\"", "", cur[grep("morph tag", cur)]))
} else {
cur_tbl$morph[i] <- "-"
}
if(length(grep(".*<pos tag=\"", cur)) > 0) {
cur_tbl$pos[i] <- gsub("\".*", "", gsub(".*<pos tag=\"", "", cur[grep("pos tag", cur)]))
} else {
cur_tbl$pos[i] <- "-"
}
}
# create CWB file
# file header
if(j == 1) {
write.table(c("<?xml version=\"1.0\" encoding=\"UTF-8\"?>", "<corpus>"),
"ren.vrt", row.names = F, col.names = F, quote = F)
}
write.table(text_header,
"ren.vrt", row.names = F, col.names = F, quote = F, append = T)
write.table(cur_tbl,
"ren.vrt", sep = "\t", row.names = F, col.names = F, quote = F, append = T)
write.table("</text>",
"ren.vrt", row.names = F, col.names = F, quote = F, append = T)
if(j == length(f)) {
write.table("</corpus>",
"ren.vrt", row.names = F, col.names = F, quote = F, append = T)
}
print(j)
}
warnings()
grep("wērden", d)
grep("wērden", d, value = T)
12650/24
gsub("\".*", "", gsub(".*<lemma_wsd tag=\"", "", cur[grep("lemma_wsd tag", cur)]))
gsub("\".*", "", gsub(".*<bound_sent tag=\"", "", cur[grep("bound_sent tag", cur)]))
cur
library(tidyverse)
# list files
f <- list.files("ReN_anno_2019-08-14/", full.names = T)
for(j in 1:length(f)) {
# read data
d <- readLines(f[j])
# get metadata
header_name <- gsub("\".*", "", gsub(".*name=\"", "", grep("<cora-header name", d, value = T)))
# get header
header_start <- grep("<header", d)
header_end   <- grep("</header", d)
hdr <- d[header_start:header_end]
hdr <- sub(":", "=\"", hdr)
hdr <- gsub("(?<=$)", "\"", hdr, perl = T)
text_header <- paste0("<text id=\"", header_name, "\"", gsub("text=\"", "text_name=\"", gsub("</?header>", "", paste0(hdr, collapse = " "))), ">", collapse = " ")
# get tokens
token_start <- grep("<token id", d)
token_end   <- grep("</token", d)
# empty table for dipl, lemma, POS, morph
cur_tbl <- tibble(
word      = character(length(token_start)),
token_id  = character(length(token_start)),
dipl      = character(length(token_start)),
lemma     = character(length(token_start)),
pos       = character(length(token_start)),
morph     = character(length(token_start)),
lemma_wsd = character(length(token_start)),
bound_sent = character(length(token_start)),
)
# extract values
for(i in 1:length(token_start)) {
cur <-d[token_start[i]:token_end[i]]
if(length(grep(".*<token id=\"", cur)) > 0) {
cur_tbl$token_id[i] <- gsub("\".*", "", gsub(".*<token id=\"", "", cur[grep("token id", cur)]))
} else {
cur_tbl$token_id[i] <- "-"
}
if(length(grep(".*<token id=\".*trans", cur)) > 0) {
cur_tbl$dipl[i] <- gsub("\".*", "", gsub(".*trans=\"", "", cur[grep("token id", cur)]))
} else {
cur_tbl$dipl[i] <- "-"
}
if(length(grep(".*<token id=\".*trans", cur)) > 0) {
cur_tbl$word[i] <- gsub("\".*", "", gsub(".*trans=\"", "", cur[grep("token id", cur)]))
} else {
cur_tbl$word[i] <- "-"
}
if(length(grep(".*<lemma tag=\"", cur)) > 0) {
cur_tbl$lemma[i] <- gsub("\".*", "", gsub(".*<lemma tag=\"", "", cur[grep("lemma tag", cur)]))
} else {
cur_tbl$lemma[i] <- "-"
}
if(length(grep(".*<lemma_wsd tag=\"", cur)) > 0) {
cur_tbl$lemma_wsd[i] <- gsub("\".*", "", gsub(".*<lemma_wsd tag=\"", "", cur[grep("lemma_wsd tag", cur)]))
} else {
cur_tbl$lemma_wsd[i] <- "-"
}
if(length(grep(".*<morph tag=\"", cur)) > 0) {
cur_tbl$morph[i] <- gsub("\".*", "", gsub(".*<morph tag=\"", "", cur[grep("morph tag", cur)]))
} else {
cur_tbl$morph[i] <- "-"
}
if(length(grep(".*<pos tag=\"", cur)) > 0) {
cur_tbl$pos[i] <- gsub("\".*", "", gsub(".*<pos tag=\"", "", cur[grep("pos tag", cur)]))
} else {
cur_tbl$pos[i] <- "-"
}
if(length(grep(".*<bound_sent tag=\"", cur)) > 0) {
cur_tbl$pos[i] <- gsub("\".*", "", gsub(".*<bound_sent tag=\"", "", cur[grep("bound_sent tag", cur)]))
} else {
cur_tbl$pos[i] <- "-"
}
}
# create CWB file
# file header
if(j == 1) {
write.table(c("<?xml version=\"1.0\" encoding=\"UTF-8\"?>", "<corpus>"),
"ren.vrt", row.names = F, col.names = F, quote = F)
}
write.table(text_header,
"ren.vrt", row.names = F, col.names = F, quote = F, append = T)
write.table(cur_tbl,
"ren.vrt", sep = "\t", row.names = F, col.names = F, quote = F, append = T)
write.table("</text>",
"ren.vrt", row.names = F, col.names = F, quote = F, append = T)
if(j == length(f)) {
write.table("</corpus>",
"ren.vrt", row.names = F, col.names = F, quote = F, append = T)
}
print(j)
}
library(tidyverse)
# list files
f <- list.files("ReN_anno_2019-08-14/", full.names = T)
for(j in 1:length(f)) {
# read data
d <- readLines(f[j])
# get metadata
header_name <- gsub("\".*", "", gsub(".*name=\"", "", grep("<cora-header name", d, value = T)))
# get header
header_start <- grep("<header", d)
header_end   <- grep("</header", d)
hdr <- d[header_start:header_end]
hdr <- sub(":", "=\"", hdr)
hdr <- gsub("(?<=$)", "\"", hdr, perl = T)
text_header <- paste0("<text id=\"", header_name, "\"", gsub("text=\"", "text_name=\"", gsub("</?header>", "", paste0(hdr, collapse = " "))), ">", collapse = " ")
# get tokens
token_start <- grep("<token id", d)
token_end   <- grep("</token", d)
# empty table for dipl, lemma, POS, morph
cur_tbl <- tibble(
word      = character(length(token_start)),
token_id  = character(length(token_start)),
dipl      = character(length(token_start)),
lemma     = character(length(token_start)),
pos       = character(length(token_start)),
morph     = character(length(token_start)),
lemma_wsd = character(length(token_start)),
bound_sent = character(length(token_start)),
)
# extract values
for(i in 1:length(token_start)) {
cur <-d[token_start[i]:token_end[i]]
if(length(grep(".*<token id=\"", cur)) > 0) {
cur_tbl$token_id[i] <- gsub("\".*", "", gsub(".*<token id=\"", "", cur[grep("token id", cur)]))
} else {
cur_tbl$token_id[i] <- "-"
}
if(length(grep(".*<token id=\".*trans", cur)) > 0) {
cur_tbl$dipl[i] <- gsub("\".*", "", gsub(".*trans=\"", "", cur[grep("token id", cur)]))
} else {
cur_tbl$dipl[i] <- "-"
}
if(length(grep(".*<token id=\".*trans", cur)) > 0) {
cur_tbl$word[i] <- gsub("\".*", "", gsub(".*trans=\"", "", cur[grep("token id", cur)]))
} else {
cur_tbl$word[i] <- "-"
}
if(length(grep(".*<lemma tag=\"", cur)) > 0) {
cur_tbl$lemma[i] <- gsub("\".*", "", gsub(".*<lemma tag=\"", "", cur[grep("lemma tag", cur)]))
} else {
cur_tbl$lemma[i] <- "-"
}
if(length(grep(".*<lemma_wsd tag=\"", cur)) > 0) {
cur_tbl$lemma_wsd[i] <- gsub("\".*", "", gsub(".*<lemma_wsd tag=\"", "", cur[grep("lemma_wsd tag", cur)]))
} else {
cur_tbl$lemma_wsd[i] <- "-"
}
if(length(grep(".*<morph tag=\"", cur)) > 0) {
cur_tbl$morph[i] <- gsub("\".*", "", gsub(".*<morph tag=\"", "", cur[grep("morph tag", cur)]))
} else {
cur_tbl$morph[i] <- "-"
}
if(length(grep(".*<pos tag=\"", cur)) > 0) {
cur_tbl$pos[i] <- gsub("\".*", "", gsub(".*<pos tag=\"", "", cur[grep("pos tag", cur)]))
} else {
cur_tbl$pos[i] <- "-"
}
if(length(grep(".*<bound_sent tag=\"", cur)) > 0) {
cur_tbl$bound_sent[i] <- gsub("\".*", "", gsub(".*<bound_sent tag=\"", "", cur[grep("bound_sent tag", cur)]))
} else {
cur_tbl$bound_sent[i] <- "-"
}
}
# create CWB file
# file header
if(j == 1) {
write.table(c("<?xml version=\"1.0\" encoding=\"UTF-8\"?>", "<corpus>"),
"ren.vrt", row.names = F, col.names = F, quote = F)
}
write.table(text_header,
"ren.vrt", row.names = F, col.names = F, quote = F, append = T)
write.table(cur_tbl,
"ren.vrt", sep = "\t", row.names = F, col.names = F, quote = F, append = T)
write.table("</text>",
"ren.vrt", row.names = F, col.names = F, quote = F, append = T)
if(j == length(f)) {
write.table("</corpus>",
"ren.vrt", row.names = F, col.names = F, quote = F, append = T)
}
print(j)
}
readLines("ren.vrt", n = 1000)
library(tidyverse)
d <- readLines("ren.vrt")
d
head(d, 200)
head(d, 20)
# find start and end of texte
grep("<text id", d)
# find start and end of texte
text_start <- grep("<text id", d)
text_end   <- grep("</text")
text_end   <- grep("</text", d)
d[text_start[1]:text_end[1]]
d[text_start[1]:text_end[1]] %>% head(20)
d[(text_end-1)]
# function for inserting line
insert_line <- function(vec, position, what) {
vec1 <- vec[1:(position-1)]
vec2 <- vec[position:length(vec)]
return(c(vec1, what, vec2))
}
# insert sentence start tag at the beginning
# of the text and sentence end tag at its end
insert_line(d, (text_start+1), "<p>") %>% head
insert_line(d, (text_end-1), "</p>")
insert_line(d, (text_end[1]-1), "</p>") %>% tail
text_end[1]
insert_line(d, (text_end[1]), "</p>") %>% tail
insert_line(d, (text_end[1]), "</p>")
insert_line(d, (text_end[1]), "</p>")[text_start[1]:text_end[1]]
d[(text_start-1)]
d[(text_end[1]-1)]
insert_line(d, (text_end[1]), "</p>")[text_start[1]:text_end[1]]
insert_line(d, (text_end[1]), "</p>")[text_start[1]:text_end[1]] %>% tail()
insert_line(d, (text_end[1]), "</p>")[text_start[1]:(text_end[1]+2)] %>% tail()
# insert sentence start tag at the beginning
# of the text and sentence end tag at its end
for(i in 1:length(text_start)) {
d <- insert_line(d, (text_start[1]+1), "<s>")
d <- insert_line(d, (text_end[1]), "</s>")
}
# insert sentence tags in-between after
# tokens with sent="Satz", except in cases where
# the </s> tag already follows
find_satz <- grep("Satz$", d)
find_satz[1:10]
insert_line(d, find_satz[1]+1, "<s>")
d[1:find_satz[1]]
# remove cases where item after find_satz is already </s>
d[find_satz+1]
# remove cases where item after find_satz is already </s>
which(d[find_satz+1] == "</s>")
# remove cases where item after find_satz is already </s>
find_satz[-which(d[find_satz+1] == "</s>")]
# remove cases where item after find_satz is already </s>
find_satz <- find_satz[-which(d[find_satz+1] == "</s>")]
find_satz
# In a second step, we add sentence boundaries
# to the data. (This could have been done before,
# but well...)
rm(list = ls())
d <- readLines("ren.vrt")
# function for inserting line
insert_line <- function(vec, position, what) {
vec1 <- vec[1:(position-1)]
vec2 <- vec[position:length(vec)]
return(c(vec1, what, vec2))
}
# find start and end of texte
text_start <- grep("<text id", d)
text_end   <- grep("</text", d)
for(i in 1:length(text_start)) {
d <- insert_line(d, (text_start[i]+1), "<s>")
d <- insert_line(d, (text_end[i]), "</s>")
text_start <- text_start+2
text_end   <- text_end+2
}
head(d, 200)
text_start[1]
d[200:300,]
d[200:300]
d[text_start[1]]
d[text_start[1]-(146*2)]
text_start[1-146*2
text_start[1]-146*2
text_end[1]-146*2
d[2240:2260]
rm(list = ls())
d <- readLines("ren.vrt")
# function for inserting line
insert_line <- function(vec, position, what) {
vec1 <- vec[1:(position-1)]
vec2 <- vec[position:length(vec)]
return(c(vec1, what, vec2))
}
# find start and end of texte
text_start <- grep("<text id", d)
text_end   <- grep("</text", d)
# insert sentence start tag at the beginning
# of the text and sentence end tag at its end
for(i in 1:length(text_start)) {
d <- insert_line(d, (text_start[i]+1), "<s>")
d <- insert_line(d, (text_end[i]+1), "</s>")
text_start <- text_start+2
text_end   <- text_end+2
}
d[2240:2260]
# insert sentence tags in-between after
# tokens with sent="Satz", except in cases where
# the </s> tag already follows
find_satz <- grep("Satz$", d)
# remove cases where item after find_satz is already </s>
find_satz <- find_satz[-which(d[find_satz+1] == "</s>")]
for(i in 1:length(find_satz)) {
d <- insert_line(d, (find_satz[i]+1), "</s>")
find_satz <- find_satz + 1
d <- insert_line(d, (find_satz[i]+1), "<s>")
find_satz <- find_satz + 1
print(i)
}
head(d, 100)
write.table(d, "ren_sentence.vrt", row.names = F, col.names = F, quote = F, append = F)
install.packages("cwbtools")
readLines("ren_sentence.vrt", 500)
readLines("ren_sentence.vrt", 500) %>% write.table("test.vrt", quote = F, row.names = F, col.names = F)
readLines("ren_sentence.vrt", 10000) %>% write.table("test.vrt", quote = F, row.names = F, col.names = F)
readLines("ren_sentence.vrt", 60000) %>% write.table("test.vrt", quote = F, row.names = F, col.names = F)
library(cwbtools)
?cwbtools::cwb_registry_dir
?`cwbtools-package`
library(tidyverse)
# list files
f <- list.files("ReN_anno_2019-08-14/", full.names = T)
j = 1
# read data
d <- readLines(f[j])
# get metadata
header_name <- gsub("\".*", "", gsub(".*name=\"", "", grep("<cora-header name", d, value = T)))
# get header
header_start <- grep("<header", d)
header_end   <- grep("</header", d)
hdr <- d[header_start:header_end]
hdr <- sub(":", "=\"", hdr)
hdr <- gsub("(?<=$)", "\"", hdr, perl = T)
text_header <- paste0("<text id=\"", header_name, "\"", gsub("text=\"", "text_name=\"", gsub("</?header>", "", paste0(hdr, collapse = " "))), ">", collapse = " ")
# get tokens
token_start <- grep("<token id", d)
token_end   <- grep("</token", d)
# empty table for dipl, lemma, POS, morph
cur_tbl <- tibble(
word      = character(length(token_start)),
token_id  = character(length(token_start)),
dipl      = character(length(token_start)),
lemma     = character(length(token_start)),
pos       = character(length(token_start)),
morph     = character(length(token_start)),
lemma_wsd = character(length(token_start)),
bound_sent = character(length(token_start)),
)
218/3
